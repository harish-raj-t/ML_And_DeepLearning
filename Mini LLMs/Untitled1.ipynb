{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3bde1b-4987-4b68-a74d-1da01d423357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "import json \n",
    "from transformers import (\n",
    "    GPT2LMHeadModel,\n",
    "    GPT2Tokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19657e6d-e9d1-4a22-9df1-bbdd8ffece40",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt2\"  \n",
    "OUTPUT_DIR = \"./finetuned-gpt2\"\n",
    "DATASET_NAME = \"Manageengine\"  \n",
    "NUM_TRAIN_EPOCHS = 3\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 5e-5\n",
    "WARMUP_STEPS = 500\n",
    "MAX_LENGTH = 512\n",
    "SAVE_STEPS = 10000\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322f0ac4-db2e-4c85-96f7-1d2978346ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4d12a5-3573-43b9-8833-7496d4bfa4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(MODEL_NAME)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "dataset = load_dataset(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "707f344b-0ef6-40f7-9edc-2eec21ba04ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAQs scraped successfully and saved to faqs.json\n"
     ]
    }
   ],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import re\n",
    "# import json\n",
    "\n",
    "# url = \"https://www.manageengine.com/products/desktop-central/faq.html\"\n",
    "# headers = {\n",
    "#     \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36\"\n",
    "# }\n",
    "# response = requests.get(url, headers=headers)\n",
    "# if response.status_code != 200:\n",
    "#     print(\"Failed to fetch the page\")\n",
    "#     exit()\n",
    "\n",
    "# soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# faqs = []\n",
    "# faq_sections = soup.find_all(\"div\", class_=\"accordion_in\")\n",
    "\n",
    "# for section in faq_sections:\n",
    "#     question = section.find(\"div\", class_=\"acc_head\").text.strip()\n",
    "#     question = re.sub(r\"^\\d+\\.\\s*\", \"\", question)\n",
    "#     answer = section.find(\"div\", class_=\"acc_content\").text.strip()\n",
    "#     faqs.append({\"question\": question, \"answer\": answer})\n",
    "\n",
    "\n",
    "\n",
    "# with open(\"faqs.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(faqs, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "# print(\"FAQs scraped successfully and saved to faqs.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40459126-2264-4dc1-a3cf-a6932aec1000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_from_qa_pairs(file_path, train_ratio=0.8):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        qa_pairs = json.load(f)\n",
    "    df = pd.DataFrame(qa_pairs)\n",
    "    df['text'] = df.apply(lambda row: f\"Question: {row['question']}\\nAnswer: {row['answer']}\", axis=1)\n",
    "    train_size = int(len(df) * train_ratio)\n",
    "    train_df = df.iloc[:train_size]\n",
    "    val_df = df.iloc[train_size:]\n",
    "    train_dataset = Dataset.from_pandas(train_df)\n",
    "    val_dataset = Dataset.from_pandas(val_df)\n",
    "    dataset_dict = DatasetDict({\n",
    "        'train': train_dataset,\n",
    "        'validation': val_dataset\n",
    "    })\n",
    "    return dataset_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236ca9f7-8e88-447d-b574-15e4946cf6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset_from_qa_pairs(\"faqs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9e1cd7-e7b0-47f5-bb55-bb53264b8a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding = \"max_length\",\n",
    "        truncation = True,\n",
    "        max_length = MAX_LENGTH\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff031c84-ef22-44b9-9752-aaf7285ec5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_fn,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"]  \n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be24381-238a-44ec-a1a4-a630704e2f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_arguments = TrainingArguments(\n",
    "    output_dir = OUTPUT_DIR,\n",
    "    overwrite_output_dir = True,\n",
    "    num_train_epochs = 3,\n",
    "    per_device_train_batch_size = BATCH_SIZE,\n",
    "    per_device_eval_batch_size = BATCH_SIZE,\n",
    "    warmup_steps = WARMUP_STEPS,\n",
    "    learning_rate = LEARNING_RATE,\n",
    "    weight_decay = 0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    save_steps=SAVE_STEPS,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=SAVE_STEPS,\n",
    "    seed=SEED,\n",
    "    fp16=torch.cuda.is_available(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e104367-a952-4606-b0fd-917830abd3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = trainer_arguments,\n",
    "    data_collator = data_collator,\n",
    "   train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7116c567-74e1-4743-88eb-5d0e87976274",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9d016d-e198-4a41-b225-cc19b0182f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af297313-c3fc-4378-92a3-18c2befe9a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def apply_rope(x, pos, dim):\n",
    "    \"\"\"\n",
    "    Applies RoPE (Rotary Positional Embeddings) to an input vector.\n",
    "    \n",
    "    Args:\n",
    "        x: Input tensor of shape (seq_len, dim)\n",
    "        pos: Position indices (seq_len,)\n",
    "        dim: Embedding dimension (must be even)\n",
    "    \n",
    "    Returns:\n",
    "        Tensor of shape (seq_len, dim) with RoPE applied.\n",
    "    \"\"\"\n",
    "    # Ensure the dimension is even for rotation\n",
    "    assert dim % 2 == 0, \"Embedding dimension must be even for RoPE\"\n",
    "\n",
    "    # Compute theta (rotation angles) for each dimension\n",
    "    theta = 1.0 / (10000 ** (2 * (np.arange(dim // 2) / dim)))\n",
    "    print(theta)\n",
    "\n",
    "    # Compute angles for each position\n",
    "    angles = np.outer(pos, theta)  # Shape: (seq_len, dim//2)\n",
    "\n",
    "    # Compute sin and cos for the rotation matrix\n",
    "    sin_angles = np.sin(angles)\n",
    "    cos_angles = np.cos(angles)\n",
    "\n",
    "    # Split input tensor into real and imaginary parts\n",
    "    x_real, x_imag = np.split(x, 2, axis=-1)  # Each of shape (seq_len, dim/2)\n",
    "\n",
    "    # Apply rotation\n",
    "    x_rotated = np.concatenate([x_real * cos_angles - x_imag * sin_angles,\n",
    "                                x_real * sin_angles + x_imag * cos_angles], axis=-1)\n",
    "\n",
    "    return x_rotated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08395696-f63b-474e-850f-9f534e378c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8892339  0.98800979 0.96360525 0.61355999]\n",
      " [0.52276888 0.35692841 0.18013395 0.01959338]\n",
      " [0.20788909 0.53627561 0.14015751 0.1703878 ]\n",
      " [0.86538056 0.51496165 0.00778109 0.79358106]\n",
      " [0.09406633 0.47596445 0.42949415 0.56032595]]\n",
      "[0 1 2 3 4]\n",
      "[1.   0.01]\n",
      "Original Embeddings:\n",
      " [[0.8892339  0.98800979 0.96360525 0.61355999]\n",
      " [0.52276888 0.35692841 0.18013395 0.01959338]\n",
      " [0.20788909 0.53627561 0.14015751 0.1703878 ]\n",
      " [0.86538056 0.51496165 0.00778109 0.79358106]\n",
      " [0.09406633 0.47596445 0.42949415 0.56032595]]\n",
      "\n",
      "RoPE Transformed Embeddings:\n",
      " [[ 0.8892339   0.98800979  0.96360525  0.61355999]\n",
      " [ 0.13087573  0.35671464  0.53722163  0.02316162]\n",
      " [-0.21395725  0.53276083  0.13070691  0.18107852]\n",
      " [-0.85781833  0.49092607  0.11441929  0.80867051]\n",
      " [ 0.26355639  0.45317667 -0.35192575  0.57891125]]\n"
     ]
    }
   ],
   "source": [
    "# Example sequence of 5 tokens with embedding size 4 (must be even)\n",
    "seq_len = 5\n",
    "dim = 4  # Must be even\n",
    "x = np.random.rand(seq_len, dim)  # Random embeddings\n",
    "\n",
    "# Define positions (0 to seq_len-1)\n",
    "positions = np.arange(seq_len)\n",
    "print(x)\n",
    "print(positions)\n",
    "# Apply RoPE\n",
    "x_rope = apply_rope(x, positions, dim)\n",
    "\n",
    "# Print results\n",
    "print(\"Original Embeddings:\\n\", x)\n",
    "print(\"\\nRoPE Transformed Embeddings:\\n\", x_rope)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026bffb2-b224-4106-9c78-e9ff3d8da439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
