{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a779d41e-6c21-4393-8c07-43ec2494082a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x295cf770>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence,pack_padded_sequence, pad_packed_sequence\n",
    "import os\n",
    "seed = 1234\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "719e84a3-73f0-45ba-89f0-77488e432358",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, emd_dim, heads=4, dropout = 0.2):\n",
    "        super().__init__()\n",
    "        assert emd_dim % heads == 0\n",
    "        self.heads = heads\n",
    "        self.head_dim = emd_dim//heads\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "        self.multiHead = nn.Linear(emd_dim, emd_dim*3)\n",
    "        self.output = nn.Linear(emd_dim,emd_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    @staticmethod\n",
    "    def add_masking(attn_scores, padding_mask):\n",
    "        col_mask = padding_mask[:, None, None, :]\n",
    "        attn_scores.masked_fill_((col_mask == 0), float('-inf'))\n",
    "        return attn_scores\n",
    "\n",
    "    def forward(self, x, padding_mask=None, attn_mask=False, kv_cache = None):\n",
    "        B, T, C = x.shape\n",
    "        qkv = self.multiHead(x)\n",
    "        q, k, v = torch.chunk(qkv,3,dim=-1)\n",
    "        q = q.view(B, T, self.heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        k = k.view(B, T, self.heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        v = v.view(B, T, self.heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) * self.scale\n",
    "        if attn_mask:\n",
    "            tril = torch.tril(torch.ones(T,T))\n",
    "            attn_scores = attn_scores.masked_fill(tril==0, float('-inf'))\n",
    "        if padding_mask is not None:\n",
    "            attn_scores = self.add_masking(attn_scores, padding_mask)\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        attn_probs_drop = self.dropout(attn_probs)\n",
    "        attn_output = torch.matmul(attn_probs_drop,v)\n",
    "        fn_attn_output = attn_output.permute(0, 2, 1, 3).reshape(B, T, C)\n",
    "        return self.output(fn_attn_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5e8af5e-7064-44d6-b756-f683303dda15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm1D(nn.Module):\n",
    "  def __init__(self, dim, eps=1e-5):\n",
    "    super(LayerNorm1D, self).__init__()\n",
    "    self.gamma = nn.Parameter(torch.ones(dim))\n",
    "    self.beta = nn.Parameter(torch.zeros(dim))\n",
    "    self.eps = eps\n",
    "\n",
    "  def forward(self, x):\n",
    "    mean = x.mean(-1,keepdim=True)\n",
    "    var = x.var(-1, unbiased=False, keepdim=True)\n",
    "    xhat = (x-mean)/torch.sqrt(var+self.eps)\n",
    "    return (self.gamma * xhat) +self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dca0f7b-9443-492a-a665-11176459212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, output_dim, dropout = 0.5):\n",
    "    super().__init__()\n",
    "    self.feed_forward_layer = nn.Sequential(\n",
    "      nn.Linear(input_dim, hidden_dim),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(hidden_dim, output_dim),\n",
    "      nn.Dropout(dropout)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.feed_forward_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9b827dd-09a5-4c32-9728-ed09e92bed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self,embed_dim, heads=4):\n",
    "        super().__init__()\n",
    "        self.layer_norm1 = LayerNorm1D(embed_dim)\n",
    "        self.layer_norm2 = LayerNorm1D(embed_dim)\n",
    "        self.multi_head_attn =  MultiHeadAttention(embed_dim, heads)\n",
    "        self.feed_forward_layer = FeedForward(embed_dim, embed_dim*4, embed_dim)\n",
    "    \n",
    "    def forward(self, x, padding_mask):\n",
    "        x = x + self.multi_head_attn(self.layer_norm1(x), padding_mask)\n",
    "        x = x + self.feed_forward_layer(self.layer_norm2(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29d36309-54f3-44a9-a2e3-76102766d4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embed_dim, heads = 4, num_layers=4):\n",
    "        super().__init__()\n",
    "        self.encoder_blocks = nn.ModuleList([EncoderBlock(embed_dim,heads) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x, padding_mask = None):\n",
    "        for block in self.encoder_blocks:\n",
    "            x = block(x, padding_mask = padding_mask) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b257f5d9-1b81-41e7-8ec9-1a1203832ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, vocab_size, max_length, segment_needed=False):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.positional_embedding = nn.Embedding(max_length, embed_dim)\n",
    "        self.segment_needed = segment_needed\n",
    "        if self.segment_needed:\n",
    "            self.segmentation_embedding = nn.Embedding(2, embed_dim)\n",
    "\n",
    "    def forward(self, x, segment_ids):\n",
    "        x_emd = self.embedding(x)\n",
    "        x_pos_emd = self.positional_embedding(torch.arange(x.shape[1]))\n",
    "        x = x_emd + x_pos_emd\n",
    "        if self.segment_needed:\n",
    "            x = x + self.segmentation_embedding(segment_ids)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc46f9af-0a7f-4db7-ab89-235c4a54b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    def __init__(self, embed_dim, vocab_size, max_length, heads = 4, num_layers = 4, dropout = 0.2):\n",
    "        super().__init__()\n",
    "        self.embedding = EmbeddingBlock(embed_dim, vocab_size, max_length, True)\n",
    "        self.encoder = Encoder(embed_dim, heads = 4, num_layers = 4)\n",
    "        self.dropout = nn.Dropout(dropout) \n",
    "        self.linear = nn.Linear(embed_dim, 1)\n",
    "\n",
    "    def forward(self, x, segment_ids, mask):\n",
    "        x = self.embedding(x, segment_ids)\n",
    "        encoder_outputs = self.encoder(x, mask)\n",
    "        cls_output = encoder_outputs[:,0,:]\n",
    "        return self.linear(cls_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fa42ed7-cd1c-405f-9299-11a64cee91b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'nsp_dataset.csv'\n",
    "df = pd.read_csv(path, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34997b5d-6db4-4613-8e3b-108f353a9101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()  \n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  \n",
    "    tokens = text.split()  \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "450599ee-8179-4d61-b8e0-7534680ec8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentence_A'] = df['sentence_A'].apply(preprocess_text)\n",
    "df['sentence_B'] = df['sentence_B'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b66a65c-367a-417c-adb5-568f54f7cfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['sentence_A'].apply(len).between(6, 30)) & (df['sentence_B'].apply(len).between(6, 30))].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fa7700e-1501-4db0-a21d-e3b9d479bd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_A = df['sentence_A']\n",
    "sentences_B = df['sentence_B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3054746-4934-42fd-8325-6427e5204362",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = []\n",
    "for tokens in sentences_A:\n",
    "    all_tokens.extend(tokens)  \n",
    "\n",
    "for tokens in sentences_B:\n",
    "    all_tokens.extend(tokens)  \n",
    "vocab = Counter(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f702a93-c7ea-48a3-a02a-012e16229a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_id = {token: idx + 3 for idx, token in enumerate(vocab)} \n",
    "token_to_id['<PAD>'] = 0\n",
    "token_to_id['<CLS>'] = 1\n",
    "token_to_id['<SEG>'] = 2\n",
    "\n",
    "id_to_token= {value:key for key,value in token_to_id.items()}\n",
    "vocab_size = len(id_to_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69457503-f2db-43e1-b4cb-738cf75ec586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(tokens,token_to_id, is_first=False):\n",
    "    tokenized_texts = [token_to_id.get(token,0) for token in tokens]\n",
    "    if is_first:\n",
    "        tokenized_texts = [1] + tokenized_texts\n",
    "    else:\n",
    "        tokenized_texts = [2] + tokenized_texts + [2]\n",
    "    return tokenized_texts\n",
    "\n",
    "sentences_A = sentences_A.apply(lambda x: tokenize_text(x, token_to_id, True))\n",
    "sentences_B = sentences_B.apply(lambda x: tokenize_text(x, token_to_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f6e2b61-bc80-41b6-b9a9-6e6ea906394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['label']==\"IsNext\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b62dbd41-9871-4fd4-a208-6744c0165904",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentencesDataset(Dataset):\n",
    "    def __init__(self, first_sequences, second_sequences, output):\n",
    "        self.first_seq = first_sequences\n",
    "        self.second_seq = second_sequences\n",
    "        self.output = output\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.first_seq)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        sentence = self.first_seq[idx] + self.second_seq[idx]\n",
    "        # segment_ids = torch.cat((torch.zeros(1, len(self.first_seq[idx])), torch.ones(1, len(self.second_seq[idx]))), dim=1)\n",
    "        segment_ids = torch.cat((\n",
    "            torch.zeros(len(self.first_seq[idx]), dtype=torch.long),\n",
    "            torch.ones(len(self.second_seq[idx]), dtype=torch.long)\n",
    "        ), dim=0)\n",
    "        return torch.tensor(sentence), segment_ids.squeeze(0), torch.tensor(self.output[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fba385f-839d-439d-b7f0-45c9aa3b01d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    X, segment_ids, y = zip(*batch)\n",
    "    X_padded = pad_sequence(X, batch_first=True, padding_value=0)\n",
    "    segment_ids_padded = pad_sequence(segment_ids, batch_first=True, padding_value=0)\n",
    "    padding_mask = (X_padded != 0) \n",
    "    return X_padded, torch.tensor(y, dtype=torch.float32).unsqueeze(1), segment_ids_padded, padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b37f741f-ed07-4571-a722-f40061e6960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_A = sentences_A[:10000]\n",
    "sentences_B = sentences_B[:10000]\n",
    "labels = labels[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37ce8f16-e08f-4f6f-bd85-36d2a75002b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SentencesDataset(sentences_A, sentences_B, labels)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True,collate_fn = collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False,collate_fn = collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f426291-dc48-462f-adbc-16302111c6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 128\n",
    "NUM_LAYERS = 4\n",
    "DROPOUT = 0.5\n",
    "VOCAB_SIZE = vocab_size  \n",
    "PAD_IDX = 0 \n",
    "MAX_LEN = max((sentences_A+sentences_B).apply(len))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05fade9f-4ce1-41e9-b2a2-f8925022a02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT( embed_dim = EMBEDDING_DIM,  vocab_size = VOCAB_SIZE, max_length = MAX_LEN, heads = 4, num_layers = 4)\n",
    "# if os.path.exists(\"Bert_next_sentence_pred_model.pth\"):\n",
    "#     model.load_state_dict(torch.load(\"Bert_next_sentence_pred_model.pth\")) \n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff65a900-53dd-47b9-974a-3773e8fab3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model :nn.Module, criterion: nn.Module, optimizer: torch.optim, train_data: DataLoader, val_data: DataLoader, epochs: int = 4):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for X, y, segment_ids, padding_mask in train_data:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X, segment_ids, padding_mask)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for X, y, segment_ids, padding_mask in val_data:\n",
    "                outputs = model(X, segment_ids, padding_mask)\n",
    "                val_loss += criterion(outputs, y).item()\n",
    "                preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "                correct += (preds == y).sum().item()\n",
    "                total += y.size(0)\n",
    "        \n",
    "        avg_train_loss = epoch_loss / len(train_data)\n",
    "        avg_val_loss = val_loss / len(val_data)\n",
    "        accuracy = correct / total\n",
    "        torch.save(model.state_dict(), \"Bert_next_sentence_pred_model.pth\")\n",
    "        print(f\"Epoch: {epoch + 1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c19dc79f-8ccb-435d-8a76-a83c22c53aa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harish-4072\\AppData\\Local\\Temp\\ipykernel_3088\\20747429.py:17: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(sentence), segment_ids.squeeze(0), torch.tensor(self.output[idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, Train Loss: 0.8212, Val Loss: 0.6975, Accuracy: 0.4875\n",
      "Epoch: 2/100, Train Loss: 0.6994, Val Loss: 0.6932, Accuracy: 0.5130\n",
      "Epoch: 3/100, Train Loss: 0.6944, Val Loss: 0.7087, Accuracy: 0.5125\n",
      "Epoch: 4/100, Train Loss: 0.6872, Val Loss: 0.7159, Accuracy: 0.5190\n",
      "Epoch: 5/100, Train Loss: 0.6762, Val Loss: 0.7237, Accuracy: 0.5135\n",
      "Epoch: 6/100, Train Loss: 0.6935, Val Loss: 0.7417, Accuracy: 0.5180\n",
      "Epoch: 7/100, Train Loss: 0.5880, Val Loss: 1.0739, Accuracy: 0.5055\n",
      "Epoch: 8/100, Train Loss: 0.5038, Val Loss: 0.9546, Accuracy: 0.5025\n",
      "Epoch: 9/100, Train Loss: 0.4544, Val Loss: 1.2830, Accuracy: 0.5110\n",
      "Epoch: 10/100, Train Loss: 0.3688, Val Loss: 1.1574, Accuracy: 0.4965\n",
      "Epoch: 11/100, Train Loss: 0.2809, Val Loss: 1.3453, Accuracy: 0.5015\n",
      "Epoch: 12/100, Train Loss: 0.2073, Val Loss: 1.5812, Accuracy: 0.4970\n",
      "Epoch: 13/100, Train Loss: 0.1646, Val Loss: 1.8606, Accuracy: 0.5070\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, criterion, optimizer, train_data, val_data, epochs)\u001b[0m\n\u001b[0;32m      7\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(X, segment_ids, padding_mask)\n\u001b[0;32m      8\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    770\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    771\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, criterion, optimizer, train_loader, val_loader, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03477455-1602-4e23-a5fb-ef4854421b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['end', '##point', 'central', 'running', ',', 'service', 'shut', '##down', 'verification', ',', 'stop', 'the', 'end', '##po', '.', 'int', 'central', 'service', 'and', 'verify', 'it', \"'\", 's', 'completely', 'stopped', ',', 'service', 'stop', 'command', ',', 'all', 'related', 'processes', 'should', 'be', 'terminated']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Sample text\n",
    "text = \"Endpoint Central running,Service Shutdown Verification,Stop the Endpo.int Central service and verify it's completely stopped,Service stop command,All related processes should be terminated\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f376012d-b2ce-4998-a60a-9d95b1473107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2203, 8400, 2430, 2770, 1010, 2326, 3844, 7698, 22616, 1010, 2644, 1996, 2203, 6873, 1012, 20014, 2430, 2326, 1998, 20410, 2009, 1005, 1055, 3294, 3030, 1010, 2326, 2644, 3094, 1010, 2035, 3141, 6194, 2323, 2022, 12527]\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33cacaf2-e741-49f8-9f1a-486d3add81f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'bert', 'is', 'amazing', '!', '[SEP]', 'Would', 'love', 'to', 'use', 'it', 'for', 'bigger', 'tasks']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(\"BERT is amazing!\")\n",
    "tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"] + [i for i in \"Would love to use it for bigger tasks\".split(\" \")]\n",
    "\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46e68ff1-d061-4cb8-8dc5-9e74eac198f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,   101,   102,     0,     0],\n",
      "        [  101, 14324,   102,     0,     0],\n",
      "        [  101,  2003,   102,     0,     0],\n",
      "        [  101,  6429,   102,     0,     0],\n",
      "        [  101,   999,   102,     0,     0],\n",
      "        [  101,   102,   102,     0,     0],\n",
      "        [  101,  2052,   102,     0,     0],\n",
      "        [  101,  2293,   102,     0,     0],\n",
      "        [  101,  2000,   102,     0,     0],\n",
      "        [  101,  2224,   102,     0,     0],\n",
      "        [  101,  2009,   102,     0,     0],\n",
      "        [  101,  2005,   102,     0,     0],\n",
      "        [  101,  7046,   102,     0,     0],\n",
      "        [  101,  8518,   102,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "encoded = tokenizer(tokens, padding=\"max_length\", truncation=False, max_length=5, return_tensors=\"pt\")\n",
    "\n",
    "print(encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b9ef640-d43b-4d87-8dfe-5eba7f01cbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "text = \"BERT is an amazing transformer model used for various NLP tasks, including question answering, sentiment analysis, and named entity recognition.\"\n",
    "\n",
    "encoded = tokenizer(text, padding=\"max_length\", max_length=10, truncation=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27d5f7e0-4621-4aff-89fb-a13083003742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 14324, 2003, 2019, 6429, 10938, 2121, 2944, 2109, 2005, 2536, 17953, 2361, 8518, 1010, 2164, 3160, 10739, 1010, 15792, 4106, 1010, 1998, 2315, 9178, 5038, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c0b563-b6e4-4000-91f7-c2b9fda0e2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
